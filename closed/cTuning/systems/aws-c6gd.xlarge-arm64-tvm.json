{
  "accelerator_frequency": "-",
  "accelerator_host_interconnect": "-",
  "accelerator_interconnect": "-",
  "accelerator_interconnect_topology": "-",
  "accelerator_memory_capacity": "-",
  "accelerator_memory_configuration": "-",
  "accelerator_model_name": "-",
  "accelerator_on-chip_memories": "-",
  "accelerators_per_node": "0",
  "cooling": "",
  "division": "closed",
  "framework": "TVM v0.8-dev",
  "host_memory_capacity": "8 GiB",
  "host_memory_configuration": "-",
  "host_networking": "-",
  "host_networking_topology": "-",
  "host_processor_caches": "L1d cache: 256 KiB; L1i cache: 256 KiB; L2 cache: 4 MiB; L3 cache: 32 MiB",
  "host_processor_core_count": "4",
  "host_processor_frequency": "3100 MHz",
  "host_processor_interconnect": "-",
  "host_processor_model_name": "Neoverse-N1 (aarch64)",
  "host_processors_per_node": "1",
  "host_storage_capacity": "237 GiB",
  "host_storage_type": "NVMe SSD",
  "hw_notes": "https://aws.amazon.com/ec2/instance-types/c6",
  "number_of_nodes": "1",
  "operating_system": "Ubuntu 20.04.2 LTS (Linux-5.8.0-1041-aws-aarch64-with-glibc2.29)",
  "other_software_stack": "GCC 9.3.0; Python 3.8.10",
  "status": "available",
  "submitter": "cTuning",
  "sw_notes": "Automated by MLCommons Collective Knowledge v2.5.8 (https://github.com/mlcommons/ck) and the CK-powered MLPerf submission workflow (https://github.com/mlcommons/ck-mlops/tree/main/module/bench.mlperf.inference)",
  "system_name": "Amazon EC2 (c6gd.xlarge)",
  "system_type": "edge"
}
