# Tensorflow Int8 Quantization for resnet50
The following instructions are based on Intel's MLPerf v0.7 Inference 
submission: [link](https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/Intel/calibration/TensorFlow)
Note the modifications that have been made.

# TensorFlow ResNet50-v1.5 for MLPerf v0.7 inference

## Description

The ResNet50 INT8 model is offline generated by [Intel Low Precision Optimization Tool](https://github.com/intel/lp-opt-tool.git) based on [FP32 model](https://zenodo.org/record/2535873/files/resnet50_v1.pb) and the calibration dataset provided by mlperf in [here](https://github.com/mlperf/inference/blob/master/calibration/ImageNet/cal_image_list_option_1.txt)

>> IntelÂ® Low Precision Optimization Tool(iLiT) is an open-source python library which is intended to deliver a unified low-precision inference interface cross multiple Intel optimized DL frameworks on both CPU and GPU. It supports automatic accuracy-driven tuning strategies, along with additional objectives like performance, model size, or memory footprint, to yield INT8 model

>> This tool(iLiT) by default supports post training static quantization, and takes "model"( FP32 model), "q_dataloader"(calibration dataloader) and "eval_dataloader"(evaluation function) as inputs. Calibration dataloader is used at calibration phase to collect tensor statistic info upon calibration dataset. Evaluation dataloader is used by iLiT to feed full validation dataset to get FP32 accuracy baseline and the accuracy of INT8 model generated by iLiT. iLiT relies on the evaluation dataloader to check if generated INT8 model meets pre-defined accuracy loss goal or not and decides whether goes through another tuning config, such as using different scheme (asym or sym), different granularity (per_tensor or per_channel), different calibration algorithm (minmax or kl).

The ResNet50 BF16 model is offline converted by auto-mixed-precision graph optimizer from TensorFlow.

## NVIDIA changes

The test harness used is based on our GPU submission and, as such, expects the
ArgMax output to be of type FP32 instead of the default INT64. 
We use GraphSurgeon to change the output dtype to match our harness's expectation.

## Steps for INT8 calibration

```bash

wget https://zenodo.org/record/2535873/files/resnet50_v1.pb
git clone git@github.com:intel/lpot.git lp-opt-tool
cd lp-opt-tool
git checkout mlperf_v0.7
python setup.py install
cd ..
git clone --recurse-submodules https://github.com/mlperf/inference.git
cd inference
git reset --hard bfbda5fc419364c3f71b5b1640f6c00e7675b212
git apply mlperf.patch
cd vision/classification_and_detection
MODEL_DIR=<dir_to_resnet50_v1.pb> DATA_DIR=<dir_to_ILSVRC2012_img_val> ./run_local.sh tf resnet50 cpu --accuracy --calib-dataset-list=../../calibration/ImageNet/cal_image_list_option_1.txt --tune
python3 change_output_dtype.py

```

A graph named int8_resnet50_v1_fp32.pb will be generated in the current working dir.

